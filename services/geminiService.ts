import { GoogleGenAI, Type } from "@google/genai";
import { AppSettings, Message, Attachment } from '../types';
import { IMAGE_MODEL, API_KEY_ENV } from '../constants';

// Helper to initialize AI with the correct key
const getAI = (settings?: AppSettings) => {
    // Priority: Settings Key -> Env Key -> Empty (will fail gracefully)
    const key = settings?.apiKey || API_KEY_ENV || '';
    if (!key) {
        throw new Error("âš ï¸ Ú©Ù„ÛŒØ¯ API ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª (âš™ï¸) Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.");
    }
    return new GoogleGenAI({ apiKey: key });
};

const getFriendlyErrorMessage = (error: any): string => {
    let msg = "";
    if (error instanceof Error) {
        msg = error.message;
    } else if (typeof error === 'object' && error !== null) {
        try {
            msg = JSON.stringify(error);
            if (error.error && error.error.message) msg = error.error.message;
            else if (error.message) msg = error.message;
        } catch {
            msg = String(error);
        }
    } else {
        msg = String(error);
    }

    if (msg.includes('429') || msg.includes('RESOURCE_EXHAUSTED') || msg.includes('quota')) {
        return "âš ï¸ Ø³Ù‚Ù Ù…Ø¬Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ (Quota) ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯Ù‚Ø§ÛŒÙ‚ÛŒ Ø¯ÛŒÚ¯Ø± ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.";
    }
    if (msg.includes('SAFETY')) {
        return "âš ï¸ Ù…Ø­ØªÙˆØ§ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.";
    }
    if (msg.includes('404') || msg.includes('NOT_FOUND')) {
        return "âš ï¸ Ù…Ø¯Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.";
    }
    if (msg.includes('API key')) {
        return "âš ï¸ Ú©Ù„ÛŒØ¯ API Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª ÛŒØ§ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.";
    }
    
    return msg.replace(/{"error":.*?}/g, "Ø®Ø·Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆØ±").substring(0, 200); 
};

export const generateContentStream = async (
  model: string,
  history: Message[],
  systemInstruction: string,
  settings: AppSettings,
  onChunk: (text: string) => void,
  signal?: AbortSignal
): Promise<{ text: string, sources: { uri: string, title: string }[] }> => {
  try {
    const ai = getAI(settings);
    const tools: any[] = [];
    if (settings.enableSearch) {
      tools.push({ googleSearch: {} });
    }

    const chatHistory = history.slice(0, -1).map(msg => {
      const parts: any[] = [];
      if (msg.content) parts.push({ text: msg.content });
      if (msg.attachments) {
          msg.attachments.forEach(att => {
              parts.push({ inlineData: { mimeType: att.mimeType, data: att.data } });
          });
      }
      return { role: msg.role, parts: parts };
    });

    const lastMsg = history[history.length - 1];
    const currentParts: any[] = [{ text: lastMsg.content }];
    if (lastMsg.attachments) {
        lastMsg.attachments.forEach(att => {
            currentParts.push({ inlineData: { mimeType: att.mimeType, data: att.data } });
        });
    }

    const chat = ai.chats.create({
      model: model,
      config: {
        systemInstruction: systemInstruction,
        temperature: settings.temperature,
        tools: tools,
      },
      history: chatHistory
    });

    const result = await chat.sendMessageStream({ 
        message: currentParts.length === 1 && currentParts[0].text ? currentParts[0].text : currentParts 
    });
    
    let fullText = "";
    let sources: { uri: string, title: string }[] = [];

    for await (const chunk of result) {
      if (signal?.aborted) throw new DOMException('Aborted', 'AbortError');
      const text = chunk.text;
      if (text) {
        fullText += text;
        onChunk(text);
      }
      const grounding = chunk.candidates?.[0]?.groundingMetadata;
      if (grounding?.groundingChunks) {
         grounding.groundingChunks.forEach((c: any) => {
             if (c.web?.uri) sources.push({ uri: c.web.uri, title: c.web.title || c.web.uri });
         });
      }
    }
    
    sources = sources.filter((v,i,a)=>a.findIndex(t=>(t.uri === v.uri))===i);
    return { text: fullText, sources };

  } catch (error: any) {
    if (error.name === 'AbortError') return { text: "ğŸš« ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù…ØªÙˆÙ‚Ù Ø´Ø¯.", sources: [] };
    console.error("Gemini Stream Error:", error);
    throw new Error(getFriendlyErrorMessage(error));
  }
};

export const generateImageContent = async (prompt: string, settings?: AppSettings): Promise<string> => {
    try {
        const ai = getAI(settings);
        const response = await ai.models.generateContent({
            model: IMAGE_MODEL,
            contents: { parts: [{ text: prompt }] },
            config: {}
        });

        for (const part of response.candidates?.[0]?.content?.parts || []) {
            if (part.inlineData) return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
        }
        
        if (response.text) throw new Error("âš ï¸ ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯ (Ù…Ø¯Ù„ Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ø¯Ø§Ø¯).");
        throw new Error("ØªØµÙˆÛŒØ±ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.");

    } catch (error: any) {
        throw new Error(getFriendlyErrorMessage(error));
    }
}

export const analyzeFile = async (
    files: File[], 
    prompt: string, 
    model: string,
    systemInstruction: string,
    settings: AppSettings
): Promise<string> => {
    try {
        const ai = getAI(settings);
        const parts: any[] = [];
        for (const file of files) {
            const base64Data = await new Promise<string>((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const res = reader.result as string;
                    resolve(res.split(',')[1]);
                };
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
            parts.push({ inlineData: { mimeType: file.type, data: base64Data } });
        }
        parts.push({ text: prompt });

        const response = await ai.models.generateContent({
            model: model,
            contents: { parts },
            config: { systemInstruction }
        });
        return response.text || "Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.";
    } catch (error: any) {
        console.error("File Analysis Error:", error);
        throw new Error(getFriendlyErrorMessage(error));
    }
}

export const analyzeImage = async (file: File, prompt: string, model: string, settings: AppSettings): Promise<string> => {
    return analyzeFile([file], prompt, model, "You are an expert image analyst.", settings);
};

export const getStepByStep = async (
    originalQuestion: string,
    originalAnswer: string,
    model: string,
    settings: AppSettings
): Promise<string> => {
    try {
        const ai = getAI(settings);
        const prompt = `Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±: ${originalQuestion}\nÙ¾Ø§Ø³Ø® Ù‚Ø¨Ù„ÛŒ Ø´Ù…Ø§: ${originalAnswer}\nÙ„Ø·ÙØ§Ù‹ Ù…Ø±Ø§Ø­Ù„ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡.`;
        const response = await ai.models.generateContent({
            model: model,
            contents: prompt
        });
        return response.text || "ØªÙˆØ¶ÛŒØ­ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.";
    } catch (error: any) {
        throw new Error(getFriendlyErrorMessage(error));
    }
}